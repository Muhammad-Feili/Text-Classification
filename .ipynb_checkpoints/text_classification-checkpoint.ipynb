{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:\n",
      "0.8253968253968254\n",
      "confusion_matrix: \n",
      "[[10  0  5  0]\n",
      " [ 0 11  3  1]\n",
      " [ 0  0 14  0]\n",
      " [ 0  0  2 17]]\n",
      "classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     english       1.00      0.67      0.80        15\n",
      "      french       1.00      0.73      0.85        15\n",
      "      german       0.58      1.00      0.74        14\n",
      "     spanish       0.94      0.89      0.92        19\n",
      "\n",
      "   micro avg       0.83      0.83      0.83        63\n",
      "   macro avg       0.88      0.82      0.83        63\n",
      "weighted avg       0.89      0.83      0.83        63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,TfidfTransformer,CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv('dataMining.csv')\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(data['content'],data['class'],test_size=float(1/3),random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "#training with using gini index for decision tree\n",
    "\n",
    "train_gini=DecisionTreeClassifier(criterion='gini',max_depth=3)\n",
    "gini_index=Pipeline([('vect_gini',TfidfVectorizer()),('tdidf_gini',TfidfTransformer()),('clfg',train_gini)])\n",
    "gini_index.fit(X_train,Y_train)\n",
    "test_pred_gini=gini_index.predict(X_test)\n",
    "print(\"accuracy:\")\n",
    "print(accuracy_score(Y_test,test_pred_gini))\n",
    "#Confusion Matrix is used to understand the trained classifier behavior over the test dataset or validate dataset.\n",
    "print(\"confusion_matrix: \")\n",
    "print(confusion_matrix(Y_test,test_pred_gini))\n",
    "print(\"classification_report:\")\n",
    "print(classification_report(Y_test,test_pred_gini))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:\n",
      "0.7301587301587301\n",
      "confusion_matrix: \n",
      "[[10  0  5  0]\n",
      " [ 0  5  3  7]\n",
      " [ 0  0 14  0]\n",
      " [ 0  0  2 17]]\n",
      "classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     english       1.00      0.67      0.80        15\n",
      "      french       1.00      0.33      0.50        15\n",
      "      german       0.58      1.00      0.74        14\n",
      "     spanish       0.71      0.89      0.79        19\n",
      "\n",
      "   micro avg       0.73      0.73      0.73        63\n",
      "   macro avg       0.82      0.72      0.71        63\n",
      "weighted avg       0.82      0.73      0.71        63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#training with using entropy (information gain) for decision tree\n",
    "\n",
    "train_entropy=DecisionTreeClassifier(criterion='entropy',max_depth=2)\n",
    "entropy=Pipeline([('vect_entropy',TfidfVectorizer()),('tdidf_entropy',TfidfTransformer()),('clfe',train_entropy)])\n",
    "entropy.fit(X_train,Y_train)\n",
    "test_pred_entropy=entropy.predict(X_test)\n",
    "print(\"accuracy:\")\n",
    "print(accuracy_score(Y_test,test_pred_entropy))\n",
    "print(\"confusion_matrix: \")\n",
    "print(confusion_matrix(Y_test,test_pred_entropy))\n",
    "print(\"classification_report:\")\n",
    "print(classification_report(Y_test,test_pred_entropy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:\n",
      "1.0\n",
      "confusion_matrix: \n",
      "[[15  0  0  0]\n",
      " [ 0 15  0  0]\n",
      " [ 0  0 14  0]\n",
      " [ 0  0  0 19]]\n",
      "classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     english       1.00      1.00      1.00        15\n",
      "      french       1.00      1.00      1.00        15\n",
      "      german       1.00      1.00      1.00        14\n",
      "     spanish       1.00      1.00      1.00        19\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        63\n",
      "   macro avg       1.00      1.00      1.00        63\n",
      "weighted avg       1.00      1.00      1.00        63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification with naive bayes method\n",
    "\"\"\"in this section the gaussian naive bayes not working for text feature extracted becaues of  sparse \n",
    "inputs are not implemented in GaussianNB is that very sparse data almost certainly does not meet the \n",
    "assumptions of the algorithm â€“ when the bulk of the values are zero, a simple Gaussian is not a good \n",
    "fit to the data, and will almost never lead to a useful classification.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB as MNB\n",
    "\n",
    "naive_bayes=Pipeline([('vect_naiveB',TfidfVectorizer()),('tdidf_naiveB',TfidfTransformer()),('clfNB',MNB())])\n",
    "naive_bayes.fit(X_train,Y_train)\n",
    "NB_pred=naive_bayes.predict(X_test)\n",
    "print(\"accuracy:\")\n",
    "print(accuracy_score(Y_test,NB_pred))\n",
    "print(\"confusion_matrix: \")\n",
    "print(confusion_matrix(Y_test,NB_pred))\n",
    "print(\"classification_report:\")\n",
    "print(classification_report(Y_test,NB_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:\n",
      "1.0\n",
      "confusion_matrix: \n",
      "[[15  0  0  0]\n",
      " [ 0 15  0  0]\n",
      " [ 0  0 14  0]\n",
      " [ 0  0  0 19]]\n",
      "classification_report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     english       1.00      1.00      1.00        15\n",
      "      french       1.00      1.00      1.00        15\n",
      "      german       1.00      1.00      1.00        14\n",
      "     spanish       1.00      1.00      1.00        19\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        63\n",
      "   macro avg       1.00      1.00      1.00        63\n",
      "weighted avg       1.00      1.00      1.00        63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification with KNearestNeighbors\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "\n",
    "KNN_clf=Pipeline([('vect_KNN',TfidfVectorizer()),('tfidf_KNN',TfidfTransformer()),('clf_KNN',KNN())])\n",
    "KNN_clf.fit(X_train,Y_train)\n",
    "KNN_pred=KNN_clf.predict(X_test)\n",
    "print(\"accuracy:\")\n",
    "print(accuracy_score(Y_test,KNN_pred))\n",
    "print(\"confusion_matrix: \")\n",
    "print(confusion_matrix(Y_test,KNN_pred))\n",
    "print(\"classification_report:\")\n",
    "print(classification_report(Y_test,KNN_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
